
% This script gives spike rate bar graphs for user-specified bin width for
% all units in a recording, WHEN THE INPUT DATA IS THE SPIKE TIMES.

% What are we naming this analysis?
promptStrings = {'expt name:'};
defaultInputs = {'Rate',};
answ = inputdlg(promptStrings,'Inputs', [1, 30],defaultInputs);
expt = answ{1,1};


% We need the bin size.
promptStrings = {'Bin size [s]:'};
defaultInputs = {'0.05',};
answ = inputdlg(promptStrings,'Inputs', [1, 30],defaultInputs);
binSz = str2double(answ(1));

   
% We also need the sampling frequency, which can change from recording
% to recording.
promptStrings = {'Sampling Frequency (fs)'};
defaultInputs = {'3.003003003003003e+04',};
answ = inputdlg(promptStrings,'Inputs', [1, 30],defaultInputs);
fs = str2double(answ(1));


% Instead of calculating a bin window and summing the samples for each window into the bin to get the counts,
% as you would for binary data, we need to get number of elements whose
% values fall between a bin size in seconds.


% Need to load AllChannels and CondSig file as well as sortedData to get the npoints and the cluster times.

% binSamples is the number of elements in spiketrain per bin.
binSamples = fs*binSz;

% Need the number of bins we're gonna pop our data into.
nBins = round(npointsAll/binSamples);


% Need to create an empty matrix that's eagerly awaiting all our cluster
% counts.
goodsIdx =cellfun(@(x) x~=3,sortedData(:,3));
goods = find(goodsIdx);
gdCells = sortedData(goods,:);
szT = length(gdCells);
counts = zeros(nBins, szT);


%RAM !!! Looks to me that this doesn't go through all the clusters, only 1 to szT
%clusters-- it correctly ignores bad clusters, but won't make it to the
%very last clusters.  I would rewrite to first kick out bad clusters (use ~= to find those clusters that aren' bad, as in cellfun call at line 36 above) then
%iterate through the remaining good clusters. This also has the benefit of
%removing "blanks" from the rate matrix.
for b = 1:szT   % cluster by cluster
        for a = 1:nBins
            fsV = fs*gdCells{b,2}'; 

            logicalfsV = (fsV >(a-1)*binSamples) & (fsV <= a*binSamples);
            counts(a,b) = sum(logicalfsV);
        end
        % rate = counts/binSz;
        % figure; bar(rate(:,b));
end
 rate = counts/binSz;
% Rate will be given in Counts per Second.
% If you had 20 counts in a half-second bin size, the rate would be 40
% counts = 20/ bin size.
% So you're dividing counts by the bin size.

% We've churned out the firing rate per cluster fo a given bin width.
% Lets plot them next to eachother to get population activity.
% Experiment time in secs for the RateMap x-axis.

% exptT = [0:nBins]'*binSz;
exptT = [0:1:npointsAll/fs];
RateMap = figure;
imagesc(exptT, [1:szT], rate');
% x-axis = exptT, y-axis = [1:szT], plot = rate'.
xlabel('Time (s)');
ylabel('Cluster No.');
title(expt);
txt = {['Bin Size = ', num2str(binSz) 's']};
text(8328.733413406633,-2.714285714285708,1.4210854715202e-14, txt);
%Use fire colormap
colormap(fire);
colorbar;

%use caxis command to hardcode colormap so that we can more easily compare
caxis([0 50]);



% Let's get the triggers on this thing

mechTTL = round(Conditions(1).Triggers/fs);
for a = mechTTL
logicalTTL(a) = true;
end


configureFigureToPDF(figure(RateMap));
saveas(figure(RateMap), expt, 'emf');
save(fullfile(dataDir, [expt]), 'rate', 'RateMap', 'binSz', '-v7.3');

  
%across conditions-- try it out with autogenerated values to get a sense of
%the appropriate scaling

%Add labels!

%RAM Can you programmatically save the figure file?
% savefig('RateMap.fig'); print('RateMap.pdf','-dpdf'); print('RateMap.emf','-dmeta');
%RAM Are you always using 50 ms or 500 ms for binsizes? Asnw: No, 1s bin size for
% these files
%RAM Add binsize to title or somewhere on plot
%RAM Wrap everything in a function as below and save in new .m file
% [fig expT rate]=myFunctionName(sortedData,fs,binSz]
%RAM programatically save results to a new data file using save command at
% command line